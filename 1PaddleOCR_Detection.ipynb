{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JQgJzL2yFRh1"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install PaddlePaddle"
      ],
      "metadata": {
        "id": "TNZB2Im-r5Mq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPvz_X1f-ty-",
        "outputId": "da75d48d-3efb-49ff-ee5c-76ba255de392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install paddlepaddle -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
        "!pip install \"paddleocr==2.7\" # Recommend to use version 2.0.1+\n"
      ],
      "metadata": {
        "id": "U7VJdrHYr74V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7a052ef8-70f2-468e-aa1b-b55607de0156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Collecting paddlepaddle\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/80/2d/594249b7ee3d0b491f46efc1c28be92624bc8eb21257e98e5723bbae2cf8/paddlepaddle-2.5.2-cp310-cp310-manylinux1_x86_64.whl (126.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from paddlepaddle)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/39/9b/4937d841aee9c2c8102d9a4eeb800c7dad25386caabb4a1bf5010df81a57/httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (9.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (4.4.2)\n",
            "Collecting astor (from paddlepaddle)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (3.20.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx->paddlepaddle)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle) (1.3.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->paddlepaddle)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->paddlepaddle) (1.2.0)\n",
            "Installing collected packages: h11, astor, httpcore, httpx, paddlepaddle\n",
            "Successfully installed astor-0.8.1 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 paddlepaddle-2.5.2\n",
            "Collecting paddleocr==2.7\n",
            "  Downloading paddleocr-2.7.0.0-py3-none-any.whl (74.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.1/74.1 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from paddleocr==2.7) (2.0.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from paddleocr==2.7) (0.19.3)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from paddleocr==2.7) (0.4.0)\n",
            "Collecting pyclipper (from paddleocr==2.7)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lmdb (from paddleocr==2.7)\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from paddleocr==2.7) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from paddleocr==2.7) (1.23.5)\n",
            "Collecting visualdl (from paddleocr==2.7)\n",
            "  Downloading visualdl-2.5.3-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz (from paddleocr==2.7)\n",
            "  Downloading rapidfuzz-3.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python<=4.6.0.66 (from paddleocr==2.7)\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-contrib-python<=4.6.0.66 (from paddleocr==2.7)\n",
            "  Downloading opencv_contrib_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from paddleocr==2.7) (3.0.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from paddleocr==2.7) (4.9.3)\n",
            "Collecting premailer (from paddleocr==2.7)\n",
            "  Downloading premailer-3.10.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from paddleocr==2.7) (3.1.2)\n",
            "Collecting attrdict (from paddleocr==2.7)\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Collecting PyMuPDF<1.21.0 (from paddleocr==2.7)\n",
            "  Downloading PyMuPDF-1.20.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow>=10.0.0 (from paddleocr==2.7)\n",
            "  Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-docx (from paddleocr==2.7)\n",
            "  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from paddleocr==2.7) (4.11.2)\n",
            "Requirement already satisfied: fonttools>=4.24.0 in /usr/local/lib/python3.10/dist-packages (from paddleocr==2.7) (4.46.0)\n",
            "Collecting fire>=0.3.0 (from paddleocr==2.7)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdf2docx (from paddleocr==2.7)\n",
            "  Downloading pdf2docx-0.5.6-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.4/148.4 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire>=0.3.0->paddleocr==2.7) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.3.0->paddleocr==2.7) (2.4.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->paddleocr==2.7) (2.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug->paddleocr==2.7) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->paddleocr==2.7) (3.7.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug->paddleocr==2.7) (2.31.6)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->paddleocr==2.7) (3.2.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->paddleocr==2.7) (2023.12.9)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->paddleocr==2.7) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->paddleocr==2.7) (23.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->paddleocr==2.7) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx->paddleocr==2.7) (4.5.0)\n",
            "Collecting cssselect (from premailer->paddleocr==2.7)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting cssutils (from premailer->paddleocr==2.7)\n",
            "  Downloading cssutils-2.9.0-py3-none-any.whl (398 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m398.5/398.5 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from premailer->paddleocr==2.7) (2.31.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from premailer->paddleocr==2.7) (5.3.2)\n",
            "Collecting bce-python-sdk (from visualdl->paddleocr==2.7)\n",
            "  Downloading bce_python_sdk-0.8.98-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flask>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from visualdl->paddleocr==2.7) (2.2.5)\n",
            "Collecting Flask-Babel>=3.0.0 (from visualdl->paddleocr==2.7)\n",
            "  Downloading flask_babel-4.0.0-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from visualdl->paddleocr==2.7) (3.20.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from visualdl->paddleocr==2.7) (1.5.3)\n",
            "Collecting rarfile (from visualdl->paddleocr==2.7)\n",
            "  Downloading rarfile-4.1-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from visualdl->paddleocr==2.7) (5.9.5)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl->paddleocr==2.7) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl->paddleocr==2.7) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl->paddleocr==2.7) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl->paddleocr==2.7) (8.1.7)\n",
            "Requirement already satisfied: Babel>=2.12 in /usr/local/lib/python3.10/dist-packages (from Flask-Babel>=3.0.0->visualdl->paddleocr==2.7) (2.14.0)\n",
            "Requirement already satisfied: pytz>=2022.7 in /usr/local/lib/python3.10/dist-packages (from Flask-Babel>=3.0.0->visualdl->paddleocr==2.7) (2023.3.post1)\n",
            "Collecting Pillow>=10.0.0 (from paddleocr==2.7)\n",
            "  Downloading Pillow-10.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodome>=3.8.0 (from bce-python-sdk->visualdl->paddleocr==2.7)\n",
            "  Downloading pycryptodome-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from bce-python-sdk->visualdl->paddleocr==2.7) (0.18.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr==2.7) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr==2.7) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr==2.7) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr==2.7) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr==2.7) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->premailer->paddleocr==2.7) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->premailer->paddleocr==2.7) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->premailer->paddleocr==2.7) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->premailer->paddleocr==2.7) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask>=1.1.1->visualdl->paddleocr==2.7) (2.1.3)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=b431d00c812dd92b411a0c372e01081c9ee7a3e0b0693b08824e174b7525d4df\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fire\n",
            "Installing collected packages: pyclipper, lmdb, rarfile, rapidfuzz, python-docx, PyMuPDF, pycryptodome, Pillow, opencv-python, opencv-contrib-python, fire, cssutils, cssselect, attrdict, premailer, pdf2docx, bce-python-sdk, Flask-Babel, visualdl, paddleocr\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.8.0.76\n",
            "    Uninstalling opencv-python-4.8.0.76:\n",
            "      Successfully uninstalled opencv-python-4.8.0.76\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.8.0.76\n",
            "    Uninstalling opencv-contrib-python-4.8.0.76:\n",
            "      Successfully uninstalled opencv-contrib-python-4.8.0.76\n",
            "Successfully installed Flask-Babel-4.0.0 Pillow-10.0.1 PyMuPDF-1.20.2 attrdict-2.0.1 bce-python-sdk-0.8.98 cssselect-1.2.0 cssutils-2.9.0 fire-0.5.0 lmdb-1.4.1 opencv-contrib-python-4.6.0.66 opencv-python-4.6.0.66 paddleocr-2.7.0.0 pdf2docx-0.5.6 premailer-3.10.0 pyclipper-1.3.0.post5 pycryptodome-3.19.0 python-docx-1.1.0 rapidfuzz-3.5.2 rarfile-4.1 visualdl-2.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "Pw-zRzB_sLrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from paddleocr import PaddleOCR,draw_ocr\n",
        "# Paddleocr supports Chinese, English, French, German, Korean and Japanese.\n",
        "# You can set the parameter `lang` as `ch`, `en`, `fr`, `german`, `korean`, `japan`\n",
        "# to switch the language model in order.\n",
        "ocr = PaddleOCR(use_angle_cls=True, lang='en') # need to run only once to download and load model into memory\n",
        "img_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/testset/full/duy.jpg'\n",
        "result = ocr.ocr(img_path, cls=True)\n",
        "for idx in range(len(result)):\n",
        "    res = result[idx]\n",
        "    for line in res:\n",
        "        print(line)\n",
        "\n",
        "\n",
        "# draw result\n",
        "from PIL import Image, ImageOps\n",
        "result = result[0]\n",
        "image = Image.open(img_path).convert('RGB')\n",
        "image = ImageOps.exif_transpose(image)\n",
        "boxes = [line[0] for line in result]\n",
        "txts = [line[1][0] for line in result]\n",
        "scores = [line[1][1] for line in result]\n",
        "im_show = draw_ocr(image, boxes, txts, scores, font_path='/content/drive/MyDrive/Colab Notebooks/AIprj/ARIAL.TTF')\n",
        "im_show = Image.fromarray(im_show)\n",
        "im_show.save('result.jpg')"
      ],
      "metadata": {
        "id": "R4oWxv6yuY-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bulk detection\n"
      ],
      "metadata": {
        "id": "JQgJzL2yFRh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from paddleocr import PaddleOCR, draw_ocr\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "# Paddleocr supports Chinese, English, French, German, Korean, and Japanese.\n",
        "# You can set the parameter `lang` as `ch`, `en`, `fr`, `german`, `korean`, `japan`\n",
        "# to switch the language model in order.\n",
        "ocr = PaddleOCR(use_angle_cls=True, lang='en')  # need to run only once to download and load the model into memory\n",
        "\n",
        "input_folder = '/content/drive/MyDrive/Colab Notebooks/AIprj/cccd_chip/'\n",
        "output_folder = '/content/drive/MyDrive/Colab Notebooks/AIprj/newtest/'\n",
        "\n",
        "# Ensure the output folder exists\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Process each image file in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
        "        img_path = os.path.join(input_folder, filename)\n",
        "        result = ocr.ocr(img_path, cls=True)\n",
        "\n",
        "        # Print OCR results\n",
        "        for idx in range(len(result)):\n",
        "            res = result[idx]\n",
        "            for line in res:\n",
        "                print(line)\n",
        "\n",
        "        # Draw result\n",
        "        result = result[0]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        image = ImageOps.exif_transpose(image)\n",
        "        boxes = [line[0] for line in result]\n",
        "        txts = [line[1][0] for line in result]\n",
        "        scores = [line[1][1] for line in result]\n",
        "        im_show = draw_ocr(image, boxes, txts, scores, font_path='/content/drive/MyDrive/Colab Notebooks/AIprj/ARIAL.TTF')\n",
        "\n",
        "        # Save the output with a unique filename based on the input filename\n",
        "        output_filename = f'result_{filename}'\n",
        "        output_path = os.path.join(output_folder, output_filename)\n",
        "        im_show = Image.fromarray(im_show)\n",
        "        im_show.save(output_path)"
      ],
      "metadata": {
        "id": "P3-5BgITCLke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detect and cut multiple images\n"
      ],
      "metadata": {
        "id": "tj7s4CC9FTu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "def cut_images_by_bbox(input_folder, output_folder, padding):\n",
        "    # Process each image file in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
        "            img_path = os.path.join(input_folder, filename)\n",
        "            result = ocr.ocr(img_path, cls=True)\n",
        "\n",
        "            # Draw result\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            image = ImageOps.exif_transpose(image)\n",
        "            for idx in range(len(result)):\n",
        "                res = result[idx]\n",
        "                boxes = [line[0] for line in res]\n",
        "                txts = [line[1][0] for line in res]\n",
        "                scores = [line[1][1] for line in res]\n",
        "                #im_show = draw_ocr(image, boxes, txts, scores, font_path='/content/drive/MyDrive/Colab Notebooks/AIprj/ARIAL.TTF')\n",
        "\n",
        "                # Save each bounding box as a separate image\n",
        "                for box, txt, score, box_idx in zip(boxes, txts, scores, range(1, len(boxes) + 1)):\n",
        "                    # Ensure valid integer coordinates\n",
        "                    x0, y0 = map(int, box[0])  # Bottom-left corner\n",
        "                    x2, y2 = map(int, box[2])  # Top-right corner\n",
        "                    x1, y1 = map(int, box[1])\n",
        "                    x3, y3 = map(int, box[3])\n",
        "                    xmin=min(x0,x1,x2,x3)\n",
        "                    xmax=max(x0,x1,x2,x3)\n",
        "                    ymin=min(y0,y1,y2,y3)\n",
        "                    ymax=max(y0,y1,y2,y3)\n",
        "\n",
        "                    # Add padding around the bounding box\n",
        "                    xmin -= padding\n",
        "                    ymin -= padding\n",
        "                    xmax += padding\n",
        "                    ymax += padding\n",
        "\n",
        "                    cropped_image = image.crop((xmin, ymin, xmax, ymax))\n",
        "\n",
        "                    # Format the output filename based on the input filename and box index\n",
        "                    output_filename = f'{os.path.splitext(filename)[0]}-{box_idx}.jpg'\n",
        "                    output_path = os.path.join(output_folder, output_filename)\n",
        "                    cropped_image.save(output_path)\n",
        "\n",
        "# Processing\n",
        "input_folder = '/content/drive/MyDrive/Colab Notebooks/AIprj/testset/full/'\n",
        "output_folder = '/content/drive/MyDrive/Colab Notebooks/AIprj/testset/cut/'\n",
        "cut_images_by_bbox(input_folder, output_folder, padding=2)\n"
      ],
      "metadata": {
        "id": "pnz_Xvk5FU_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eval metric\n"
      ],
      "metadata": {
        "id": "0YWzC8d_Qkqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write detected bounding box's coordinate to a text file"
      ],
      "metadata": {
        "id": "srvwqyZNhUVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from paddleocr import PaddleOCR, draw_ocr\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "# Paddleocr supports Chinese, English, French, German, Korean, and Japanese.\n",
        "# You can set the parameter `lang` as `ch`, `en`, `fr`, `german`, `korean`, `japan`\n",
        "# to switch the language model in order.\n",
        "ocr = PaddleOCR(use_angle_cls=True, lang='en')  # need to run only once to download and load the model into memory\n",
        "\n",
        "input_folder = '/content/drive/MyDrive/Colab Notebooks/AIprj/tempo/'\n",
        "output_folder = '/content/drive/MyDrive/Colab Notebooks/AIprj/eval_detect/preds/'\n",
        "\n",
        "# Ensure the output folder exists\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Process each image file in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
        "        img_path = os.path.join(input_folder, filename)\n",
        "        result = ocr.ocr(img_path, cls=True)\n",
        "\n",
        "        # Write OCR results to a text file\n",
        "        output_filename_txt = f'{os.path.splitext(filename)[0]}.txt'\n",
        "        output_path_txt = os.path.join(output_folder, output_filename_txt)\n",
        "\n",
        "        with open(output_path_txt, 'w', encoding='utf-8') as txt_file:\n",
        "            for idx in range(len(result)):\n",
        "                res = result[idx]\n",
        "                for line in res:\n",
        "                    txt_file.write(str(line) + '\\n')\n"
      ],
      "metadata": {
        "id": "eS3ZFDrzQl0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function"
      ],
      "metadata": {
        "id": "VRMxW2oNhcm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "def getGT(json_file_path):\n",
        "    # Load JSON data from the file\n",
        "    with open(json_file_path, 'r') as json_file:\n",
        "        data = json.load(json_file)\n",
        "    # Extract information from shapes\n",
        "    shapes = data.get('shapes', [])\n",
        "    # Format the output as a list of dictionaries\n",
        "    output_list = []\n",
        "    for shape in shapes:\n",
        "        points = shape.get('points', [])\n",
        "        # Create a dictionary for each shape with the desired order of keys\n",
        "        shape_dict = {\n",
        "            'points': points,\n",
        "            'text': shape.get('label', ''),  # You may need to adjust this based on your actual data\n",
        "            'ignore': False,  # You can set this based on your criteria\n",
        "        }\n",
        "        # Append the dictionary to the output list\n",
        "        output_list.append(shape_dict)\n",
        "    # Create gts\n",
        "    formatted_output = [output_list]\n",
        "    gts = formatted_output\n",
        "    return gts\n",
        "import ast\n",
        "def getPred(file_path):\n",
        "    # Initialize a list to store the extracted information\n",
        "    extracted_info = []\n",
        "    # Read the file and parse the string representation of the list\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            # Parse the string representation of the list using ast.literal_eval\n",
        "            data = ast.literal_eval(line.strip())\n",
        "\n",
        "            # Extract information from the parsed data\n",
        "            points = data[0]\n",
        "\n",
        "            # Create a dictionary with the extracted information, setting 'text' to an empty string\n",
        "            item = {\n",
        "                'points': points,\n",
        "                'text': '',\n",
        "                'ignore': False,\n",
        "            }\n",
        "            # Append the dictionary to the list\n",
        "            extracted_info.append(item)\n",
        "    # Print the result in the specified format with square brackets\n",
        "    preds = []\n",
        "    preds.append(extracted_info)\n",
        "    return preds\n",
        "\n",
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "from collections import namedtuple\n",
        "import numpy as np\n",
        "from shapely.geometry import Polygon\n",
        "\"\"\"\n",
        "reference from :\n",
        "https://github.com/MhLiao/DB/blob/3c32b808d4412680310d3d28eeb6a2d5bf1566c5/concern/icdar2015_eval/detection/iou.py#L8\n",
        "\"\"\"\n",
        "# https://github.com/PaddlePaddle/PaddleOCR/blob/b13f99607653c220ba94df2a8650edac086b0f37/ppocr/metrics/eval_det_iou.py\n",
        "false = False\n",
        "class DetectionIoUEvaluator(object):\n",
        "    def __init__(self, iou_constraint=0.5, area_precision_constraint=0.5):\n",
        "        self.iou_constraint = iou_constraint\n",
        "        self.area_precision_constraint = area_precision_constraint\n",
        "\n",
        "    def evaluate_image(self, gt, pred):\n",
        "        def get_union(pD, pG):\n",
        "            return Polygon(pD).union(Polygon(pG)).area\n",
        "\n",
        "        def get_intersection_over_union(pD, pG):\n",
        "            return get_intersection(pD, pG) / get_union(pD, pG)\n",
        "\n",
        "        def get_intersection(pD, pG):\n",
        "            return Polygon(pD).intersection(Polygon(pG)).area\n",
        "\n",
        "        def compute_ap(confList, matchList, numGtCare):\n",
        "            correct = 0\n",
        "            AP = 0\n",
        "            if len(confList) > 0:\n",
        "                confList = np.array(confList)\n",
        "                matchList = np.array(matchList)\n",
        "                sorted_ind = np.argsort(-confList)\n",
        "                confList = confList[sorted_ind]\n",
        "                matchList = matchList[sorted_ind]\n",
        "                for n in range(len(confList)):\n",
        "                    match = matchList[n]\n",
        "                    if match:\n",
        "                        correct += 1\n",
        "                        AP += float(correct) / (n + 1)\n",
        "\n",
        "                if numGtCare > 0:\n",
        "                    AP /= numGtCare\n",
        "\n",
        "            return AP\n",
        "\n",
        "        perSampleMetrics = {}\n",
        "\n",
        "        matchedSum = 0\n",
        "\n",
        "        Rectangle = namedtuple('Rectangle', 'xmin ymin xmax ymax')\n",
        "\n",
        "        numGlobalCareGt = 0\n",
        "        numGlobalCareDet = 0\n",
        "\n",
        "        arrGlobalConfidences = []\n",
        "        arrGlobalMatches = []\n",
        "\n",
        "        recall = 0\n",
        "        precision = 0\n",
        "        hmean = 0\n",
        "\n",
        "        detMatched = 0\n",
        "\n",
        "        iouMat = np.empty([1, 1])\n",
        "\n",
        "        gtPols = []\n",
        "        detPols = []\n",
        "\n",
        "        gtPolPoints = []\n",
        "        detPolPoints = []\n",
        "\n",
        "        # Array of Ground Truth Polygons' keys marked as don't Care\n",
        "        gtDontCarePolsNum = []\n",
        "        # Array of Detected Polygons' matched with a don't Care GT\n",
        "        detDontCarePolsNum = []\n",
        "\n",
        "        pairs = []\n",
        "        detMatchedNums = []\n",
        "\n",
        "        arrSampleConfidences = []\n",
        "        arrSampleMatch = []\n",
        "\n",
        "        evaluationLog = \"\"\n",
        "\n",
        "        for n in range(len(gt)):\n",
        "            points = gt[n]['points']\n",
        "            dontCare = gt[n]['ignore']\n",
        "            if not Polygon(points).is_valid:\n",
        "                continue\n",
        "\n",
        "            gtPol = points\n",
        "            gtPols.append(gtPol)\n",
        "            gtPolPoints.append(points)\n",
        "            if dontCare:\n",
        "                gtDontCarePolsNum.append(len(gtPols) - 1)\n",
        "\n",
        "        evaluationLog += \"GT polygons: \" + str(len(gtPols)) + (\n",
        "            \" (\" + str(len(gtDontCarePolsNum)) + \" don't care)\\n\"\n",
        "            if len(gtDontCarePolsNum) > 0 else \"\\n\")\n",
        "\n",
        "        for n in range(len(pred)):\n",
        "            points = pred[n]['points']\n",
        "            if not Polygon(points).is_valid:\n",
        "                continue\n",
        "\n",
        "            detPol = points\n",
        "            detPols.append(detPol)\n",
        "            detPolPoints.append(points)\n",
        "            if len(gtDontCarePolsNum) > 0:\n",
        "                for dontCarePol in gtDontCarePolsNum:\n",
        "                    dontCarePol = gtPols[dontCarePol]\n",
        "                    intersected_area = get_intersection(dontCarePol, detPol)\n",
        "                    pdDimensions = Polygon(detPol).area\n",
        "                    precision = 0 if pdDimensions == 0 else intersected_area / pdDimensions\n",
        "                    if (precision > self.area_precision_constraint):\n",
        "                        detDontCarePolsNum.append(len(detPols) - 1)\n",
        "                        break\n",
        "\n",
        "        evaluationLog += \"DET polygons: \" + str(len(detPols)) + (\n",
        "            \" (\" + str(len(detDontCarePolsNum)) + \" don't care)\\n\"\n",
        "            if len(detDontCarePolsNum) > 0 else \"\\n\")\n",
        "\n",
        "        if len(gtPols) > 0 and len(detPols) > 0:\n",
        "            # Calculate IoU and precision matrixs\n",
        "            outputShape = [len(gtPols), len(detPols)]\n",
        "            iouMat = np.empty(outputShape)\n",
        "            gtRectMat = np.zeros(len(gtPols), np.int8)\n",
        "            detRectMat = np.zeros(len(detPols), np.int8)\n",
        "            for gtNum in range(len(gtPols)):\n",
        "                for detNum in range(len(detPols)):\n",
        "                    pG = gtPols[gtNum]\n",
        "                    pD = detPols[detNum]\n",
        "                    iouMat[gtNum, detNum] = get_intersection_over_union(pD, pG)\n",
        "\n",
        "            for gtNum in range(len(gtPols)):\n",
        "                for detNum in range(len(detPols)):\n",
        "                    if gtRectMat[gtNum] == 0 and detRectMat[\n",
        "                            detNum] == 0 and gtNum not in gtDontCarePolsNum and detNum not in detDontCarePolsNum:\n",
        "                        if iouMat[gtNum, detNum] > self.iou_constraint:\n",
        "                            gtRectMat[gtNum] = 1\n",
        "                            detRectMat[detNum] = 1\n",
        "                            detMatched += 1\n",
        "                            pairs.append({'gt': gtNum, 'det': detNum})\n",
        "                            detMatchedNums.append(detNum)\n",
        "                            evaluationLog += \"Match GT #\" + \\\n",
        "                                             str(gtNum) + \" with Det #\" + str(detNum) + \"\\n\"\n",
        "\n",
        "        numGtCare = (len(gtPols) - len(gtDontCarePolsNum))\n",
        "        numDetCare = (len(detPols) - len(detDontCarePolsNum))\n",
        "        if numGtCare == 0:\n",
        "            recall = float(1)\n",
        "            precision = float(0) if numDetCare > 0 else float(1)\n",
        "        else:\n",
        "            recall = float(detMatched) / numGtCare\n",
        "            precision = 0 if numDetCare == 0 else float(detMatched) / numDetCare\n",
        "\n",
        "        hmean = 0 if (precision + recall) == 0 else 2.0 * \\\n",
        "                                                    precision * recall / (precision + recall)\n",
        "\n",
        "        matchedSum += detMatched\n",
        "        numGlobalCareGt += numGtCare\n",
        "        numGlobalCareDet += numDetCare\n",
        "\n",
        "        perSampleMetrics = {\n",
        "            'gtCare': numGtCare,\n",
        "            'detCare': numDetCare,\n",
        "            'detMatched': detMatched,\n",
        "        }\n",
        "        return perSampleMetrics\n",
        "\n",
        "    def combine_results(self, results):\n",
        "        numGlobalCareGt = 0\n",
        "        numGlobalCareDet = 0\n",
        "        matchedSum = 0\n",
        "        for result in results:\n",
        "            numGlobalCareGt += result['gtCare']\n",
        "            numGlobalCareDet += result['detCare']\n",
        "            matchedSum += result['detMatched']\n",
        "\n",
        "        methodRecall = 0 if numGlobalCareGt == 0 else float(\n",
        "            matchedSum) / numGlobalCareGt\n",
        "        methodPrecision = 0 if numGlobalCareDet == 0 else float(\n",
        "            matchedSum) / numGlobalCareDet\n",
        "        methodHmean = 0 if methodRecall + methodPrecision == 0 else 2 * \\\n",
        "                                                                    methodRecall * methodPrecision / (\n",
        "                                                                            methodRecall + methodPrecision)\n",
        "        methodMetrics = {\n",
        "            'precision': methodPrecision,\n",
        "            'recall': methodRecall,\n",
        "            'hmean': methodHmean\n",
        "        }\n",
        "\n",
        "        return methodMetrics\n"
      ],
      "metadata": {
        "id": "d_xM3dAlcCkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input single path"
      ],
      "metadata": {
        "id": "IwUN47GetBBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to your JSON file\n",
        "json_file_path = \"/content/10.json\"\n",
        "# Specify the file path\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/eval_detect/1.txt'\n",
        "#\n",
        "evaluator = DetectionIoUEvaluator()\n",
        "results = []\n",
        "for gt, pred in zip(gts, preds):\n",
        "    results.append(evaluator.evaluate_image(gt, pred))\n",
        "metrics = evaluator.combine_results(results)\n",
        "print(metrics)"
      ],
      "metadata": {
        "id": "d3lxZJPWtEgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input folder path"
      ],
      "metadata": {
        "id": "4Z3t8CpywU0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gts_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/eval_detect/gts/'\n",
        "preds_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/eval_detect/preds/'\n",
        "\n",
        "# Get the list of filenames in each folder\n",
        "gts_files = os.listdir(gts_path)\n",
        "preds_files = os.listdir(preds_path)\n",
        "\n",
        "# Ensure the lists are sorted\n",
        "gts_files.sort()\n",
        "preds_files.sort()\n",
        "#\n",
        "total_precision = 0\n",
        "total_recall = 0\n",
        "total_hmean = 0\n",
        "total_samples = 0\n",
        "# Iterate through corresponding files in both folders\n",
        "for file1, file2 in zip(gts_files, preds_files):\n",
        "    file1_path = os.path.join(gts_path, file1)\n",
        "    file2_path = os.path.join(preds_path, file2)\n",
        "    # Process\n",
        "    #\n",
        "    gts = getGT(file1_path)\n",
        "    #\n",
        "    preds = getPred(file2_path)\n",
        "    #\n",
        "    evaluator = DetectionIoUEvaluator()\n",
        "    results = []\n",
        "    for gt, pred in zip(gts, preds):\n",
        "        results.append(evaluator.evaluate_image(gt, pred))\n",
        "    metrics = evaluator.combine_results(results)\n",
        "    print(metrics)\n",
        "    # Accumulate metrics for averaging\n",
        "    total_precision += metrics['precision']\n",
        "    total_recall += metrics['recall']\n",
        "    total_hmean += metrics['hmean']\n",
        "    total_samples += 1\n",
        "\n",
        "# Calculate averages\n",
        "avg_precision = total_precision / total_samples\n",
        "avg_recall = total_recall / total_samples\n",
        "avg_hmean = total_hmean / total_samples\n",
        "\n",
        "# Print averages\n",
        "print(\"Average Precision: {:.5f}\".format(avg_precision))\n",
        "print(\"Average Recall: {:.5f}\".format(avg_recall))\n",
        "print(\"Average Hmean Score: {:.5f}\".format(avg_hmean))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuGSy3rWu1py",
        "outputId": "c165fc1e-eb89-4594-b8f7-e47060e32107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'precision': 0.8888888888888888, 'recall': 0.8421052631578947, 'hmean': 0.8648648648648649}\n",
            "{'precision': 0.8235294117647058, 'recall': 0.8235294117647058, 'hmean': 0.8235294117647058}\n",
            "{'precision': 0.875, 'recall': 0.7368421052631579, 'hmean': 0.7999999999999999}\n",
            "{'precision': 0.8823529411764706, 'recall': 0.8823529411764706, 'hmean': 0.8823529411764706}\n",
            "{'precision': 0.7647058823529411, 'recall': 0.7647058823529411, 'hmean': 0.7647058823529412}\n",
            "{'precision': 0.8823529411764706, 'recall': 0.8333333333333334, 'hmean': 0.8571428571428571}\n",
            "{'precision': 0.9285714285714286, 'recall': 0.7222222222222222, 'hmean': 0.8125000000000001}\n",
            "{'precision': 1.0, 'recall': 0.9411764705882353, 'hmean': 0.9696969696969697}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 1.0, 'recall': 0.8823529411764706, 'hmean': 0.9375}\n",
            "{'precision': 0.8421052631578947, 'recall': 0.8888888888888888, 'hmean': 0.8648648648648649}\n",
            "{'precision': 0.9444444444444444, 'recall': 1.0, 'hmean': 0.9714285714285714}\n",
            "{'precision': 0.7619047619047619, 'recall': 0.8888888888888888, 'hmean': 0.8205128205128205}\n",
            "{'precision': 0.8888888888888888, 'recall': 0.9411764705882353, 'hmean': 0.9142857142857143}\n",
            "{'precision': 0.7894736842105263, 'recall': 0.8333333333333334, 'hmean': 0.8108108108108109}\n",
            "{'precision': 0.7777777777777778, 'recall': 0.7777777777777778, 'hmean': 0.7777777777777778}\n",
            "{'precision': 0.8421052631578947, 'recall': 0.8888888888888888, 'hmean': 0.8648648648648649}\n",
            "{'precision': 0.7142857142857143, 'recall': 0.8333333333333334, 'hmean': 0.7692307692307692}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 0.7368421052631579, 'recall': 0.7777777777777778, 'hmean': 0.7567567567567567}\n",
            "{'precision': 0.7, 'recall': 0.8235294117647058, 'hmean': 0.7567567567567567}\n",
            "{'precision': 0.7777777777777778, 'recall': 0.8235294117647058, 'hmean': 0.7999999999999999}\n",
            "{'precision': 0.8421052631578947, 'recall': 0.8888888888888888, 'hmean': 0.8648648648648649}\n",
            "{'precision': 0.7777777777777778, 'recall': 0.8235294117647058, 'hmean': 0.7999999999999999}\n",
            "{'precision': 0.8888888888888888, 'recall': 0.8888888888888888, 'hmean': 0.8888888888888888}\n",
            "{'precision': 0.8888888888888888, 'recall': 0.8888888888888888, 'hmean': 0.8888888888888888}\n",
            "{'precision': 1.0, 'recall': 0.9444444444444444, 'hmean': 0.9714285714285714}\n",
            "{'precision': 0.6923076923076923, 'recall': 0.8181818181818182, 'hmean': 0.7500000000000001}\n",
            "{'precision': 0.8, 'recall': 0.9230769230769231, 'hmean': 0.8571428571428571}\n",
            "{'precision': 0.6666666666666666, 'recall': 0.7777777777777778, 'hmean': 0.717948717948718}\n",
            "{'precision': 0.47058823529411764, 'recall': 0.6153846153846154, 'hmean': 0.5333333333333333}\n",
            "{'precision': 0.85, 'recall': 0.9444444444444444, 'hmean': 0.8947368421052632}\n",
            "{'precision': 0.6842105263157895, 'recall': 0.7222222222222222, 'hmean': 0.7027027027027027}\n",
            "{'precision': 0.5714285714285714, 'recall': 0.7058823529411765, 'hmean': 0.6315789473684211}\n",
            "{'precision': 0.8421052631578947, 'recall': 0.8888888888888888, 'hmean': 0.8648648648648649}\n",
            "{'precision': 0.7857142857142857, 'recall': 0.8461538461538461, 'hmean': 0.8148148148148148}\n",
            "{'precision': 0.8947368421052632, 'recall': 0.9444444444444444, 'hmean': 0.918918918918919}\n",
            "{'precision': 0.7222222222222222, 'recall': 0.7647058823529411, 'hmean': 0.7428571428571428}\n",
            "{'precision': 0.8, 'recall': 0.8888888888888888, 'hmean': 0.8421052631578948}\n",
            "{'precision': 0.8823529411764706, 'recall': 0.8333333333333334, 'hmean': 0.8571428571428571}\n",
            "{'precision': 0.8947368421052632, 'recall': 0.9444444444444444, 'hmean': 0.918918918918919}\n",
            "{'precision': 0.7894736842105263, 'recall': 0.8333333333333334, 'hmean': 0.8108108108108109}\n",
            "{'precision': 0.7142857142857143, 'recall': 0.8333333333333334, 'hmean': 0.7692307692307692}\n",
            "{'precision': 0.8823529411764706, 'recall': 0.8333333333333334, 'hmean': 0.8571428571428571}\n",
            "{'precision': 0.8421052631578947, 'recall': 0.9411764705882353, 'hmean': 0.8888888888888888}\n",
            "{'precision': 0.8823529411764706, 'recall': 0.8333333333333334, 'hmean': 0.8571428571428571}\n",
            "{'precision': 0.631578947368421, 'recall': 0.631578947368421, 'hmean': 0.631578947368421}\n",
            "{'precision': 0.8235294117647058, 'recall': 0.7777777777777778, 'hmean': 0.7999999999999999}\n",
            "{'precision': 0.6842105263157895, 'recall': 0.7222222222222222, 'hmean': 0.7027027027027027}\n",
            "{'precision': 0.5, 'recall': 0.5384615384615384, 'hmean': 0.5185185185185186}\n",
            "{'precision': 0.8571428571428571, 'recall': 0.8, 'hmean': 0.8275862068965518}\n",
            "{'precision': 0.7894736842105263, 'recall': 0.75, 'hmean': 0.7692307692307692}\n",
            "{'precision': 0.7777777777777778, 'recall': 0.7368421052631579, 'hmean': 0.7567567567567567}\n",
            "{'precision': 0.8235294117647058, 'recall': 0.7777777777777778, 'hmean': 0.7999999999999999}\n",
            "{'precision': 0.7777777777777778, 'recall': 0.6666666666666666, 'hmean': 0.717948717948718}\n",
            "{'precision': 0.9444444444444444, 'recall': 1.0, 'hmean': 0.9714285714285714}\n",
            "{'precision': 0.5882352941176471, 'recall': 0.5, 'hmean': 0.5405405405405405}\n",
            "{'precision': 0.6666666666666666, 'recall': 0.6, 'hmean': 0.631578947368421}\n",
            "{'precision': 0.7058823529411765, 'recall': 0.631578947368421, 'hmean': 0.6666666666666667}\n",
            "{'precision': 0.7, 'recall': 0.7, 'hmean': 0.7}\n",
            "{'precision': 0.65, 'recall': 0.6190476190476191, 'hmean': 0.6341463414634146}\n",
            "{'precision': 0.7368421052631579, 'recall': 0.6666666666666666, 'hmean': 0.7}\n",
            "{'precision': 0.75, 'recall': 0.7894736842105263, 'hmean': 0.7692307692307692}\n",
            "{'precision': 0.4444444444444444, 'recall': 0.4, 'hmean': 0.4210526315789474}\n",
            "{'precision': 0.6666666666666666, 'recall': 0.5714285714285714, 'hmean': 0.6153846153846153}\n",
            "{'precision': 0.8947368421052632, 'recall': 0.8095238095238095, 'hmean': 0.8500000000000001}\n",
            "{'precision': 0.8823529411764706, 'recall': 0.8823529411764706, 'hmean': 0.8823529411764706}\n",
            "{'precision': 0.6190476190476191, 'recall': 0.6842105263157895, 'hmean': 0.6500000000000001}\n",
            "{'precision': 0.85, 'recall': 0.8095238095238095, 'hmean': 0.8292682926829269}\n",
            "{'precision': 0.6666666666666666, 'recall': 0.7, 'hmean': 0.6829268292682926}\n",
            "{'precision': 0.6842105263157895, 'recall': 0.6190476190476191, 'hmean': 0.6500000000000001}\n",
            "{'precision': 0.6666666666666666, 'recall': 0.7142857142857143, 'hmean': 0.689655172413793}\n",
            "{'precision': 0.8888888888888888, 'recall': 0.8421052631578947, 'hmean': 0.8648648648648649}\n",
            "{'precision': 0.75, 'recall': 0.6818181818181818, 'hmean': 0.7142857142857143}\n",
            "{'precision': 0.4666666666666667, 'recall': 0.5, 'hmean': 0.4827586206896552}\n",
            "{'precision': 0.631578947368421, 'recall': 0.6, 'hmean': 0.6153846153846154}\n",
            "{'precision': 0.8461538461538461, 'recall': 0.7857142857142857, 'hmean': 0.8148148148148148}\n",
            "{'precision': 0.8823529411764706, 'recall': 0.8823529411764706, 'hmean': 0.8823529411764706}\n",
            "{'precision': 0.7142857142857143, 'recall': 0.7142857142857143, 'hmean': 0.7142857142857143}\n",
            "{'precision': 0.7894736842105263, 'recall': 0.75, 'hmean': 0.7692307692307692}\n",
            "{'precision': 0.65, 'recall': 0.6190476190476191, 'hmean': 0.6341463414634146}\n",
            "{'precision': 0.5789473684210527, 'recall': 0.5789473684210527, 'hmean': 0.5789473684210527}\n",
            "{'precision': 0.6842105263157895, 'recall': 0.6842105263157895, 'hmean': 0.6842105263157895}\n",
            "{'precision': 0.7647058823529411, 'recall': 0.7647058823529411, 'hmean': 0.7647058823529412}\n",
            "{'precision': 0.6666666666666666, 'recall': 0.5714285714285714, 'hmean': 0.6153846153846153}\n",
            "{'precision': 0.6666666666666666, 'recall': 0.6153846153846154, 'hmean': 0.64}\n",
            "{'precision': 0.6923076923076923, 'recall': 0.5625, 'hmean': 0.6206896551724138}\n",
            "{'precision': 0.631578947368421, 'recall': 0.631578947368421, 'hmean': 0.631578947368421}\n",
            "{'precision': 0.8333333333333334, 'recall': 0.8823529411764706, 'hmean': 0.8571428571428571}\n",
            "{'precision': 0.7777777777777778, 'recall': 0.7, 'hmean': 0.7368421052631577}\n",
            "{'precision': 0.7368421052631579, 'recall': 0.6666666666666666, 'hmean': 0.7}\n",
            "{'precision': 0.6666666666666666, 'recall': 0.7368421052631579, 'hmean': 0.7}\n",
            "{'precision': 0.7777777777777778, 'recall': 0.6666666666666666, 'hmean': 0.717948717948718}\n",
            "{'precision': 0.85, 'recall': 0.8095238095238095, 'hmean': 0.8292682926829269}\n",
            "{'precision': 0.6, 'recall': 0.6, 'hmean': 0.6}\n",
            "{'precision': 0.8235294117647058, 'recall': 0.6666666666666666, 'hmean': 0.7368421052631577}\n",
            "{'precision': 0.7368421052631579, 'recall': 0.6666666666666666, 'hmean': 0.7}\n",
            "{'precision': 0.7222222222222222, 'recall': 0.6190476190476191, 'hmean': 0.6666666666666666}\n",
            "{'precision': 0.8947368421052632, 'recall': 0.85, 'hmean': 0.8717948717948718}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 0.7857142857142857, 'recall': 0.9166666666666666, 'hmean': 0.8461538461538461}\n",
            "{'precision': 0.7142857142857143, 'recall': 0.8333333333333334, 'hmean': 0.7692307692307692}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 0.9230769230769231, 'recall': 1.0, 'hmean': 0.9600000000000001}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 0.6875, 'recall': 0.8461538461538461, 'hmean': 0.7586206896551724}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 1.0, 'recall': 0.9166666666666666, 'hmean': 0.9565217391304348}\n",
            "{'precision': 1.0, 'recall': 1.0, 'hmean': 1.0}\n",
            "{'precision': 0.9230769230769231, 'recall': 1.0, 'hmean': 0.9600000000000001}\n",
            "{'precision': 0.9230769230769231, 'recall': 1.0, 'hmean': 0.9600000000000001}\n",
            "{'precision': 0.9230769230769231, 'recall': 1.0, 'hmean': 0.9600000000000001}\n",
            "Average Precision: 0.81463\n",
            "Average Recall: 0.81635\n",
            "Average Hmean Score: 0.81396\n"
          ]
        }
      ]
    }
  ]
}