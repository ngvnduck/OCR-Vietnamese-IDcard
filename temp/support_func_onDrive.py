# -*- coding: utf-8 -*-
"""0Support.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QcpDxPt9VDqqzNEzW0UgZBNNF7Bx4wyR
"""

def compute_accuracy(ground_truth, predictions, mode='full_sequence'):
    """
    Computes accuracy
    :param ground_truth:
    :param predictions:
    :param display: Whether to print values to stdout
    :param mode: if 'per_char' is selected then
                 single_label_accuracy = correct_predicted_char_nums_of_single_sample / single_label_char_nums
                 avg_label_accuracy = sum(single_label_accuracy) / label_nums
                 if 'full_sequence' is selected then
                 single_label_accuracy = 1 if the prediction result is exactly the same as label else 0
                 avg_label_accuracy = sum(single_label_accuracy) / label_nums
    :return: avg_label_accuracy
    """
    if mode == 'per_char':

        accuracy = []

        for index, label in enumerate(ground_truth):
            prediction = predictions[index]
            total_count = len(label)
            correct_count = 0
            try:
                for i, tmp in enumerate(label):
                    if tmp == prediction[i]:
                        correct_count += 1
            except IndexError:
                continue
            finally:
                try:
                    accuracy.append(correct_count / total_count)
                except ZeroDivisionError:
                    if len(prediction) == 0:
                        accuracy.append(1)
                    else:
                        accuracy.append(0)
        avg_accuracy = np.mean(np.array(accuracy).astype(np.float32), axis=0)
    elif mode == 'full_sequence':
        try:
            correct_count = 0
            for index, label in enumerate(ground_truth):
                prediction = predictions[index]
                if prediction == label:
                    correct_count += 1
            avg_accuracy = correct_count / len(ground_truth)
        except ZeroDivisionError:
            if not predictions:
                avg_accuracy = 1
            else:
                avg_accuracy = 0
    else:
        raise NotImplementedError('Other accuracy compute mode has not been implemented')

    return avg_accuracy

import os
import numpy as np

def compute_accuracy_from_folders(folder1, folder2, mode='full_sequence'):
    """
    Computes accuracy for pairs of text files in two folders
    :param folder1: Path to the first folder containing text files
    :param folder2: Path to the second folder containing text files
    :param mode: Accuracy computation mode ('per_char' or 'full_sequence')
    :return: Average accuracy across all pairs
    """
    # Get the list of files in each folder
    files1 = sorted(os.listdir(folder1))
    files2 = sorted(os.listdir(folder2))

    # Check if the number of files in each folder is the same
    if len(files1) != len(files2):
        raise ValueError("The number of files in the two folders must be the same")

    accuracies = []

    for file1, file2 in zip(files1, files2):
        # Construct the full paths to the text files
        path1 = os.path.join(folder1, file1)
        path2 = os.path.join(folder2, file2)

        # Read the content of the text files
        with open(path1, 'r') as f1, open(path2, 'r') as f2:
            ground_truth = f1.read().strip()
            prediction = f2.read().strip()

        # Compute accuracy for the pair
        pair_accuracy = compute_accuracy([ground_truth], [prediction], mode=mode)
        accuracies.append(pair_accuracy)

    # Calculate the average accuracy across all pairs
    avg_accuracy = np.mean(np.array(accuracies).astype(np.float32), axis=0)

    return avg_accuracy

# Example usage:
folder1_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/testset/gts/'
folder2_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/testset/preds2/'
average_accuracy = compute_accuracy_from_folders(folder1_path, folder2_path, mode='per_char')
print(f"Acc per char: {average_accuracy}")
average_accuracy = compute_accuracy_from_folders(folder1_path, folder2_path, mode='full_sequence')
print(f"Acc full seq: {average_accuracy}")

"""# VẼ"""

import re
import matplotlib.pyplot as plt

# Đọc nội dung từ tệp tin
file_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/log/log4.txt'  # Thay thế bằng đường dẫn thực tế của tệp tin
with open(file_path, 'r', encoding='utf-8') as file:
    content = file.read()

# Tạo danh sách để lưu thông tin iter, train loss, và valid loss
iter_list = []
train_loss_list = []
valid_loss_list = []

# Sử dụng biểu thức chính quy để trích xuất thông tin
pattern_train_iter = re.compile(r'iter: (\d+) - train loss: ([\d.]+)')
pattern_valid_iter = re.compile(r'iter: (\d+) - valid loss: ([\d.]+)')

# Tìm kiếm và trích xuất thông tin từ văn bản
matches_train_iter = pattern_train_iter.findall(content)
matches_valid_iter = pattern_valid_iter.findall(content)

# Lưu thông tin vào danh sách
for match in matches_train_iter:
    iter_list.append(int(match[0]))
    train_loss_list.append(float(match[1]))

for match in matches_valid_iter:
    valid_loss_list.append(float(match[1]))

# Vẽ đồ thị
plt.plot(iter_list, train_loss_list, label='Train Loss', linestyle='-', marker='o')
plt.plot(iter_list, valid_loss_list, label='Valid Loss', linestyle='-', marker='o')
plt.xlabel('Iter')
plt.ylabel('Loss')
plt.title('Đồ thị Train Loss và Valid Loss theo Iter')
plt.legend()
plt.show()

import re
import matplotlib.pyplot as plt
# Đọc nội dung từ tệp tin
file_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/log/log4.txt'  # Thay thế bằng đường dẫn thực tế của tệp tin
with open(file_path, 'r', encoding='utf-8') as file:
    content = file.read()

# Tạo danh sách để lưu thông tin iter và valid loss
iter_list = []
valid_loss_list = []

# Sử dụng biểu thức chính quy để trích xuất thông tin
pattern_valid_iter = re.compile(r'iter: (\d+) - valid loss: ([\d.]+)')

# Tìm kiếm và trích xuất thông tin từ văn bản
matches_valid_iter = pattern_valid_iter.findall(content)

# Lưu thông tin vào danh sách
for match in matches_valid_iter:
    iter_list.append(int(match[0]))
    valid_loss_list.append(float(match[1]))

# Vẽ đồ thị
plt.plot(iter_list, valid_loss_list, label='Valid Loss')
plt.xlabel('Iter')
plt.ylabel('Valid Loss')
plt.title('Đồ thị Valid Loss theo Iter')
plt.legend()
plt.show()

"""# Vẽ acc valid"""

import re
import matplotlib.pyplot as plt

# Đọc dữ liệu từ file txt
with open('/content/drive/MyDrive/Colab Notebooks/AIprj/log/log4.txt', 'r') as file:
    log_lines = file.readlines()

# Khởi tạo các danh sách để lưu trữ giá trị
iters = []
acc_full_seq = []
acc_per_char = []

# Biểu thức chính quy để trích xuất thông tin từ các dòng
pattern = re.compile(r"iter: (\d+) - valid loss: ([\d.]+) - acc full seq: ([\d.]+) - acc per char: ([\d.]+)")

# Lặp qua từng dòng trong log_lines
for line in log_lines:
    # Tìm kiếm thông tin sử dụng biểu thức chính quy
    match = pattern.search(line)

    # Kiểm tra xem có trùng khớp không
    if match:
        # Lấy giá trị từ trùng khớp và thêm vào các danh sách
        iter_val = int(match.group(1))
        acc_full_seq_val = float(match.group(3))
        acc_per_char_val = float(match.group(4))

        iters.append(iter_val)
        acc_full_seq.append(acc_full_seq_val)
        acc_per_char.append(acc_per_char_val)

# In ra các giá trị đã lấy
#print("Iterations:", iters)
#print("Accuracy (Full Seq):", acc_full_seq)
#print("Accuracy (Per Char):", acc_per_char)
# Vẽ đồ thị
plt.figure(figsize=(10, 6))
plt.plot(iters, acc_full_seq, label='Accuracy (Full Seq)')
plt.plot(iters, acc_per_char, label='Accuracy (Per Char)')

# Đặt tên cho trục và đồ thị
plt.xlabel('Iterations')
plt.ylabel('Accuracy')
plt.title('Validation Accuracy over Iterations')
plt.legend()

# Hiển thị đồ thị
plt.show()

"""# sửa lỗi '\ufeff'"""

input_file_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/img/output/train.txt'
output_file_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/img/output/train.txt'

with open(input_file_path, 'r', encoding='utf-8-sig') as input_file:
    # Read lines from the input file
    lines = input_file.readlines()

# Remove the BOM character from each line
lines_without_bom = [line.replace('\ufeff', '') for line in lines]

with open(output_file_path, 'w', encoding='utf-8') as output_file:
    # Write the modified lines to the output file
    output_file.writelines(lines_without_bom)

import os

input_folder_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/eval_recognition/preds4/'
output_folder_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/eval_recognition/preds4/'

# Ensure the output folder exists
os.makedirs(output_folder_path, exist_ok=True)

# Iterate over all files in the input folder
for filename in os.listdir(input_folder_path):
    input_file_path = os.path.join(input_folder_path, filename)
    output_file_path = os.path.join(output_folder_path, filename)

    with open(input_file_path, 'r', encoding='utf-8-sig') as input_file:
        # Read lines from the input file
        lines = input_file.readlines()

    # Remove the BOM character from each line
    lines_without_bom = [line.replace('\ufeff', '') for line in lines]

    with open(output_file_path, 'w', encoding='utf-8') as output_file:
        # Write the modified lines to the output file
        output_file.writelines(lines_without_bom)

"""# thêm path vào đầu dòng"""

input_file_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/output/train_annotation.txt'
output_file_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/output/train_annotation.txt'

# Open the input file for reading
with open(input_file_path, 'r') as input_file:
    # Read all lines from the input file
    lines = input_file.readlines()

# Modify each line by adding the prefix
modified_lines = ['output/' + line.strip() for line in lines]

# Open the output file for writing
with open(output_file_path, 'w') as output_file:
    # Write the modified lines to the output file
    output_file.write('\n'.join(modified_lines))

"""# unique"""

import os

folder1_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/eval_recognition/preds4/'
folder2_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/eval_recognition/gts4/'

# Get the list of files in each folder
files_folder1 = set(os.listdir(folder1_path))
files_folder2 = set(os.listdir(folder2_path))

# Find files that don't appear in both folders
unique_files_folder1 = files_folder1 - files_folder2
unique_files_folder2 = files_folder2 - files_folder1

# Print the results
print("Files unique to folder1:", unique_files_folder1)
print("Files unique to folder2:", unique_files_folder2)

"""# copy to"""

import os
import shutil

def copy_files(source_folder, destination_folder):
    # Get a list of all files in the source folder
    files = os.listdir(source_folder)

    # Ensure the destination folder exists, create it if not
    os.makedirs(destination_folder, exist_ok=True)

    # Iterate through each file and copy it to the destination folder
    for file_name in files:
        # Construct the full path to the source file
        source_file_path = os.path.join(source_folder, file_name)

        # Construct the full path to the destination file
        destination_file_path = os.path.join(destination_folder, file_name)

        # Copy the file to the destination folder
        shutil.copy2(source_file_path, destination_file_path)

if __name__ == "__main__":
    source_folder = '/content/drive/MyDrive/Colab Notebooks/AIprj/chip3/'  # Change this to the path of your source folder
    destination_folder = '/content/drive/MyDrive/Colab Notebooks/AIprj/cccd_chip/'  # Change this to the path of your destination folder

    copy_files(source_folder, destination_folder)

"""# count"""

import os

def count_files_in_folder(folder_path):
    # Get a list of all files in the specified folder
    files = os.listdir(folder_path)

    # Count the number of files
    num_files = len(files)

    return num_files

# Example usage
folder_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/eval_recognition/'
num_files = count_files_in_folder(folder_path)

print(f"Number of files in the folder: {num_files}")

"""# rename"""

import os

def add_prefix_to_files(folder_path, prefix='c'):
    # Get a list of all files in the specified folder
    files = os.listdir(folder_path)

    # Iterate through each file and rename it with the prefix
    for file_name in files:
        # Construct the full path to the file
        old_file_path = os.path.join(folder_path, file_name)

        # Add the prefix to the file name
        new_file_name = f"{prefix}{file_name}"

        # Construct the full path to the new file
        new_file_path = os.path.join(folder_path, new_file_name)

        # Rename the file
        os.rename(old_file_path, new_file_path)

if __name__ == "__main__":
    folder_path = '/content/drive/MyDrive/Colab Notebooks/AIprj'  # Change this to the path of your folder
    add_prefix_to_files(folder_path)

"""#  word to txt"""

!pip install python-docx

from docx import Document
import os

def convert_docx_to_txt(docx_path, txt_path):
    doc = Document(docx_path)
    with open(txt_path, 'w', encoding='utf-8') as txt_file:
        for paragraph in doc.paragraphs:
            txt_file.write(paragraph.text + '\n')

def batch_convert_docx_to_txt(docx_folder, txt_folder):
    if not os.path.exists(txt_folder):
        os.makedirs(txt_folder)

    docx_files = [f for f in os.listdir(docx_folder) if f.endswith('.docx')]

    for docx_file in docx_files:
        docx_path = os.path.join(docx_folder, docx_file)
        txt_file = os.path.splitext(docx_file)[0] + '.txt'
        txt_path = os.path.join(txt_folder, txt_file)
        convert_docx_to_txt(docx_path, txt_path)

# Replace these paths with the actual paths of your DOCX and TXT folders
docx_folder_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/doc/'
txt_folder_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/test/'

batch_convert_docx_to_txt(docx_folder_path, txt_folder_path)

"""# merge txt

"""

import os

def combine_txt_files(folder_path, output_file):
    # Get a list of all text files in the specified folder and sort them
    files = sorted(os.listdir(folder_path))

    # Open the output file for writing with the '.txt' extension
    with open(output_file, 'w') as output:
        # Loop through each text file
        for file_name in files:
            # Build the full path to the current text file
            txt_file_path = os.path.join(folder_path, file_name)

            # Extract the content from each text file
            with open(txt_file_path, 'r') as current_file:
                content = current_file.read().strip()

            # Change the file extension to '.jpg'
            jpg_file_name = os.path.splitext(file_name)[0] + '.jpg'

            # Write the filename (with '.jpg') and content to the output file separated by a tab
            output.write(f"{jpg_file_name}\t{content}\n")

if __name__ == "__main__":
    folder_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/testset/gts/'  # Change this to the path of your folder
    output_file = '/content/drive/MyDrive/Colab Notebooks/AIprj/testset/merggg.txt'
    combine_txt_files(folder_path, output_file)

"""# split"""

import os

def separate_merged_file_with_txt_extension(merged_file, output_folder):
    # Create the output folder if it doesn't exist
    os.makedirs(output_folder, exist_ok=True)

    # Read the content of the merged file
    with open(merged_file, 'r') as merged:
        lines = merged.readlines()

    # Process each line and separate it into individual text files with ".txt" extension
    file_count = 0
    for line in lines:
        # Split the line into filename and content
        parts = line.strip().split('\t', 1)
        if len(parts) == 2:
            filename, content = parts
            # Change the file extension to ".txt"
            filename = os.path.splitext(filename)[0] + ".txt"
            # Build the path to the output text file
            output_file_path = os.path.join(output_folder, filename)
            # Write the content to the output text file
            with open(output_file_path, 'w') as output_file:
                output_file.write(content)
            file_count += 1

    print(f"Number of files created: {file_count}")

# Example usage
merged_file_path = '/content/merggg.txt'
output_folder_path = '/content/drive/MyDrive/Colab Notebooks/AIprj/testset/gts/'

separate_merged_file_with_txt_extension(merged_file_path, output_folder_path)

"""# sort"""

def rearrange_lines(input_file, output_file):
    # Read all lines from the input file
    with open(input_file, 'r') as file:
        lines = file.readlines()

    # Sort the lines based on the file names at the beginning of each line
    sorted_lines = sorted(lines, key=lambda line: line.split('\t')[0])

    # Write the sorted lines to the output file
    with open(output_file, 'w') as file:
        file.writelines(sorted_lines)

if __name__ == "__main__":
    input_file = '/content/drive/MyDrive/Colab Notebooks/test/merge/test.txt'
    output_file = '/content/drive/MyDrive/Colab Notebooks/test/merge/final.txt'
    rearrange_lines(input_file, output_file)

"""# .txt to .jpg"""

def rearrange_lines_and_change_extension(input_file, output_file, new_extension):
    # Read all lines from the input file
    with open(input_file, 'r') as file:
        lines = file.readlines()

    # Sort the lines based on the file names at the beginning of each line
    sorted_lines = sorted(lines, key=lambda line: line.split('\t')[0])

    # Change the file extension to the new extension
    modified_lines = [line.replace(".txt", f".{new_extension}", 1) for line in sorted_lines]

    # Write the modified lines to the output file
    with open(output_file, 'w') as file:
        file.writelines(modified_lines)

if __name__ == "__main__":
    input_file = '/content/drive/MyDrive/Colab Notebooks/test/merge/merger.txt'
    output_file = '/content/drive/MyDrive/Colab Notebooks/test/merge/merger.txt'
    new_extension = 'jpg'
    rearrange_lines_and_change_extension(input_file, output_file, new_extension)

"""# test"""

import os
from PIL import Image
from vietocr.tool.predictor import Predictor
from vietocr.tool.config import Cfg

config = Cfg.load_config_from_name('vgg_transformer')

# config['weights'] = './weights/transformerocr.pth'
config['cnn']['pretrained'] = False
config['device'] = 'cpu'

detector = Predictor(config)

sample_folder = '/content/drive/MyDrive/Colab Notebooks/AIprj/output/'
output_file = '/content/drive/MyDrive/Colab Notebooks/AIprj/eval_recognition/merged_predictions.txt'

# Open the output file for writing
with open(output_file, 'w', encoding='utf-8') as output_file:
    # Loop through each file in the sample folder
    for filename in os.listdir(sample_folder):
        if filename.endswith(('.jpg', '.jpeg', '.png')):
            # Construct the full path to the image
            img_path = os.path.join(sample_folder, filename)

            # Open the image using PIL
            img = Image.open(img_path)

            # Perform the prediction using the detector
            prediction = detector.predict(img)

            # Write the prediction to the output file with the desired format using tabs
            output_file.write(f"{filename}\t{prediction}\n")

# Print a message indicating the completion of writing predictions
print("ok")